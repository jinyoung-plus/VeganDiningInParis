{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install --upgrade selenium urllib3\n",
    "#pip install --upgrade webdriver-manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in c:\\users\\tipss\\anaconda3\\lib\\site-packages (4.26.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.26 in c:\\users\\tipss\\anaconda3\\lib\\site-packages (from urllib3[socks]<3,>=1.26->selenium) (2.2.3)\n",
      "Requirement already satisfied: trio~=0.17 in c:\\users\\tipss\\anaconda3\\lib\\site-packages (from selenium) (0.26.2)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in c:\\users\\tipss\\anaconda3\\lib\\site-packages (from selenium) (0.11.1)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in c:\\users\\tipss\\anaconda3\\lib\\site-packages (from selenium) (2024.8.30)\n",
      "Requirement already satisfied: typing_extensions~=4.9 in c:\\users\\tipss\\anaconda3\\lib\\site-packages (from selenium) (4.11.0)\n",
      "Requirement already satisfied: websocket-client~=1.8 in c:\\users\\tipss\\anaconda3\\lib\\site-packages (from selenium) (1.8.0)\n",
      "Requirement already satisfied: attrs>=23.2.0 in c:\\users\\tipss\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (24.2.0)\n",
      "Requirement already satisfied: sortedcontainers in c:\\users\\tipss\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: idna in c:\\users\\tipss\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (3.7)\n",
      "Requirement already satisfied: outcome in c:\\users\\tipss\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.3.0.post0)\n",
      "Requirement already satisfied: sniffio>=1.3.0 in c:\\users\\tipss\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.3.0)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\users\\tipss\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.17.1)\n",
      "Requirement already satisfied: wsproto>=0.14 in c:\\users\\tipss\\anaconda3\\lib\\site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in c:\\users\\tipss\\anaconda3\\lib\\site-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\tipss\\anaconda3\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.21)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in c:\\users\\tipss\\anaconda3\\lib\\site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping links on page 1...\n",
      "Scraping links on page 2...\n",
      "Scraping links on page 3...\n",
      "Scraping links on page 4...\n",
      "Scraping links on page 5...\n",
      "Scraping links on page 6...\n",
      "Scraping links on page 7...\n",
      "Scraping links on page 8...\n",
      "Scraping links on page 9...\n",
      "Scraping links on page 10...\n",
      "Scraping links on page 11...\n",
      "Scraping links on page 12...\n",
      "Scraping links on page 13...\n",
      "Scraping links on page 14...\n",
      "Scraping links on page 15...\n",
      "Last page reached.\n",
      "Data saved to output/restaurant_links.json\n",
      "Data saved to output/restaurant_details.json\n"
     ]
    }
   ],
   "source": [
    "########## code for gathering information on vegetarian restaurants in Paris from yelp site\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import json\n",
    "import time\n",
    "import os\n",
    "import re  # Added for regular expressions\n",
    "\n",
    "def extract_restaurant_details(driver, link):\n",
    "    \"\"\"\n",
    "    Extract detailed information about a restaurant, including:\n",
    "    Name, Rating, Reviews Count, Category, Address, and up to 5 reviews.\n",
    "    \"\"\"\n",
    "    details = {\n",
    "        \"Name\": \"N/A\",\n",
    "        \"Rating\": \"N/A\",\n",
    "        \"Reviews_Count\": \"N/A\",\n",
    "        \"Category\": \"N/A\",\n",
    "        \"Address\": \"N/A\",\n",
    "        \"Reviews\": []\n",
    "    }\n",
    "    try:\n",
    "        driver.get(link)\n",
    "        time.sleep(3)  # Wait for the page to load\n",
    "\n",
    "        # Extract the restaurant's name (mandatory field)\n",
    "        try:\n",
    "            details[\"Name\"] = driver.find_element(By.CSS_SELECTOR, \"h1.y-css-olzveb\").text.strip()\n",
    "        except Exception as e:\n",
    "            print(f\"Error extracting name: {e}\")\n",
    "\n",
    "        # Extract the restaurant's rating (optional field)\n",
    "        try:\n",
    "            rating_text = driver.find_element(By.CSS_SELECTOR, \"span.y-css-1jz061g\").text.strip()\n",
    "            # Extract only numbers or set \"N/A\" if no numbers are found\n",
    "            details[\"Rating\"] = rating_text if re.match(r\"^\\d+(\\.\\d+)?$\", rating_text) else \"N/A\"\n",
    "        except:\n",
    "            details[\"Rating\"] = \"N/A\"\n",
    "\n",
    "        # Extract the number of reviews (optional field)\n",
    "        try:\n",
    "            reviews_count = driver.find_element(By.CSS_SELECTOR, \"a.y-css-1ijjqcc\").text.strip()\n",
    "            reviews_count_cleaned = reviews_count.replace(\"(\", \"\").replace(\")\", \"\").split()[0]\n",
    "            # Extract only numbers or set \"N/A\" if no numbers are found\n",
    "            details[\"Reviews_Count\"] = reviews_count_cleaned if reviews_count_cleaned.isdigit() else \"N/A\"\n",
    "        except:\n",
    "            details[\"Reviews_Count\"] = \"N/A\"\n",
    "\n",
    "        # Extract the restaurant's category (mandatory field)\n",
    "        try:\n",
    "            details[\"Category\"] = driver.find_element(By.CSS_SELECTOR, \"span.y-css-1cafv3i\").text.strip()\n",
    "        except Exception as e:\n",
    "            print(f\"Error extracting category: {e}\")\n",
    "\n",
    "        # Extract the restaurant's address (mandatory field)\n",
    "        try:\n",
    "            details[\"Address\"] = driver.find_element(By.CSS_SELECTOR, \"p.y-css-jbomhy\").text.strip()\n",
    "        except Exception as e:\n",
    "            details[\"Address\"] = \"N/A\"  # Set to \"N/A\" if address is not found\n",
    "\n",
    "        # Extract up to 5 reviews (optional field)\n",
    "        try:\n",
    "            WebDriverWait(driver, 10).until(\n",
    "                EC.presence_of_all_elements_located((By.CSS_SELECTOR, \"p.comment__09f24__D0cxf span.raw__09f24__T4Ezm\"))\n",
    "            )\n",
    "            review_elements = driver.find_elements(By.CSS_SELECTOR, \"p.comment__09f24__D0cxf span.raw__09f24__T4Ezm\")\n",
    "            for review_element in review_elements[:5]:  # Limit to 5 reviews\n",
    "                details[\"Reviews\"].append(review_element.text.strip())\n",
    "        except:\n",
    "            details[\"Reviews\"] = []\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting details for {link}: {e}\")\n",
    "\n",
    "    return details\n",
    "\n",
    "def get_all_restaurant_links(driver):\n",
    "    \"\"\"Visit all pages to collect restaurant links\"\"\"\n",
    "    base_url = \"https://www.yelp.fr/search?find_desc=Restaurants&find_loc=Paris&cflt=vegetarian\"\n",
    "    driver.get(base_url)\n",
    "\n",
    "    links = []\n",
    "    page = 1\n",
    "    while True:\n",
    "        print(f\"Scraping links on page {page}...\")\n",
    "        try:\n",
    "            # Wait for the page to load\n",
    "            WebDriverWait(driver, 10).until(\n",
    "                EC.presence_of_all_elements_located((By.CSS_SELECTOR, \"div[data-testid='serp-ia-card']\"))\n",
    "            )\n",
    "            restaurant_cards = driver.find_elements(By.CSS_SELECTOR, \"div[data-testid='serp-ia-card']\")\n",
    "            \n",
    "            for card in restaurant_cards:\n",
    "                try:\n",
    "                    link = card.find_element(By.CSS_SELECTOR, \"a.y-css-1ijjqcc\").get_attribute(\"href\").strip()\n",
    "                    if link:\n",
    "                        links.append(link)\n",
    "                except:\n",
    "                    continue\n",
    "            \n",
    "            # Move to the next page\n",
    "            next_button = driver.find_elements(By.CSS_SELECTOR, \"a.next-link\")\n",
    "            if next_button:\n",
    "                driver.execute_script(\"arguments[0].click();\", next_button[0])\n",
    "                time.sleep(5)  # Wait after page navigation\n",
    "                page += 1\n",
    "            else:\n",
    "                print(\"Last page reached.\")\n",
    "                break\n",
    "        except Exception as e:\n",
    "            print(f\"Error on page {page}: {e}\")\n",
    "            break\n",
    "\n",
    "    return links\n",
    "\n",
    "\n",
    "def save_to_json(data, filename):\n",
    "    \"\"\"Save data to a JSON file\"\"\"\n",
    "    output_path = f\"output/{filename}\"\n",
    "    os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "    with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(data, f, ensure_ascii=False, indent=4)\n",
    "    print(f\"Data saved to {output_path}\")\n",
    "\n",
    "def main():\n",
    "    chrome_driver_path = \"C:/Users/tipss/Downloads/chromedriver-win64/chromedriver.exe\"\n",
    "    service = Service(chrome_driver_path)\n",
    "    options = webdriver.ChromeOptions()\n",
    "    options.add_argument(\"--start-maximized\")\n",
    "    driver = webdriver.Chrome(service=service, options=options)\n",
    "\n",
    "    try:\n",
    "        # Step 1: Collect all restaurant links\n",
    "        restaurant_links = get_all_restaurant_links(driver)\n",
    "        save_to_json(restaurant_links, \"restaurant_links.json\")\n",
    "\n",
    "        # Step 2: Visit each link to collect detailed information and reviews\n",
    "        all_restaurant_details = []\n",
    "        total_links = len(restaurant_links)\n",
    "\n",
    "        for idx, link in enumerate(restaurant_links, start=1):\n",
    "            print(f\"Scraping details for restaurant {idx}/{total_links}: {link}\")\n",
    "            restaurant_details = extract_restaurant_details(driver, link)\n",
    "            all_restaurant_details.append(restaurant_details)\n",
    "\n",
    "        # Save the results to restaurant_details.json\n",
    "        save_to_json(all_restaurant_details, \"restaurant_details.json\")\n",
    "\n",
    "    finally:\n",
    "        driver.quit()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
